{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Workshop 2 - HTML Parising with BeautifulSoup\n",
    "Prepared by: Nickolas K. Freeman, Ph.D.\n",
    "\n",
    "In this notebook, we will see how we can use Python to harvest data from HTML. In particular, we will be using the python `requests` and `beautifulsoup` libraries to request and parse financial data from Yahoo finance. \n",
    "\n",
    "The following code block imports some libraries that we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yahoo Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be harvesting data from `https://finance.yahoo.com`. Before starting, let's first look at the `robots.txt` file published for the site to see if there is any activity that is specifically *disallowed* or if any additional guidelines for access are given. The following code block makes a **GET** request for the site's `robots.txt` file and prints the returned text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-agent: *\n",
      "Sitemap: https://finance.yahoo.com/sitemap_en-us_desktop_index.xml\n",
      "Sitemap: https://finance.yahoo.com/sitemaps/finance-sitemap_index_US_en-US.xml.gz\n",
      "Sitemap: https://finance.yahoo.com/sitemaps/finance-sitemap_googlenewsindex_US_en-US.xml.gz\n",
      "Disallow: /r/\n",
      "Disallow: /_finance_doubledown/\n",
      "Disallow: /nel_ms/\n",
      "Disallow: /caas/\n",
      "Disallow: /__rapidworker-1.2.js\n",
      "Disallow: /__blank\n",
      "Disallow: /_td_api\n",
      "Disallow: /_remote\n",
      "User-agent:googlebot\n",
      "Disallow: /m/\n",
      "\n",
      "User-agent:googlebot-news\n",
      "Disallow: /m/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_user_agent = 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36'\n",
    "\n",
    "my_headers = {'User-Agent': my_user_agent, \n",
    "             'Referer': 'https://www.google.com'}\n",
    "\n",
    "r = requests.get('https://finance.yahoo.com/robots.txt', headers = my_headers)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the `robots.txt` file specifies several paths that are disallowed for all user-agents. This is indicated by the `User-agent: *` line. However, also note that the files provides several sitemaps that actually help programs determine the layout of the site. We will use one of these sitemaps to help us access stock information for companies operating in specific sectors. Before doing this, let's store a list of prohibited paths so that we can ensure we do not volate the `robots.txt` directives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://finance.yahoo.com/r/',\n",
       " 'https://finance.yahoo.com/_finance_doubledown/',\n",
       " 'https://finance.yahoo.com/nel_ms/',\n",
       " 'https://finance.yahoo.com/caas/',\n",
       " 'https://finance.yahoo.com/__rapidworker-1.2.j',\n",
       " 'https://finance.yahoo.com/__blank',\n",
       " 'https://finance.yahoo.com/_td_ap',\n",
       " 'https://finance.yahoo.com/_remote',\n",
       " 'https://finance.yahoo.com/m/',\n",
       " 'https://finance.yahoo.com/m/']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prohibited_paths = []\n",
    "for statement in r.text.split('\\n'):\n",
    "    if 'Disallow:' in statement:\n",
    "        current_path = statement.strip('Disallow: ')\n",
    "        prohibited_paths.append('https://finance.yahoo.com' + current_path)\n",
    "prohibited_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block makes a **GET** request for the first sitemap. The response from this request is stored in the variable `r`. We use the `content` attribute of this response to get a *bytes* representation of the reponse and use the *BeautifulSoup* library to convert this data into a `soup` object. We print a *prettified* version of the first 1,000 characters of this object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\"?>\n",
      "<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n",
      " <url>\n",
      "  <loc>\n",
      "   https://finance.yahoo.com/blogs/author/andy-serwer/\n",
      "  </loc>\n",
      " </url>\n",
      " <url>\n",
      "  <loc>\n",
      "   https://finance.yahoo.com/blogs/author/brittany-jones-cooper/\n",
      "  </loc>\n",
      " </url>\n",
      " <url>\n",
      "  <loc>\n",
      "   https://finance.yahoo.com/blogs/author/daniel-howley-20160419/\n",
      "  </loc>\n",
      " </url>\n",
      " <url>\n",
      "  <loc>\n",
      "   https://finance.yahoo.com/blogs/author/daniel-roberts/\n",
      "  </loc>\n",
      " </url>\n",
      " <url>\n",
      "  <loc>\n",
      "   https://finance.yahoo.com/blogs/author/julia-la-roche/\n",
      "  </loc>\n",
      " </url>\n",
      " <url>\n",
      "  <loc>\n",
      "   https://finance.yahoo.com/blogs/author/mandi-woodruff/\n",
      "  </loc>\n",
      " </url>\n",
      " <url>\n",
      "  <loc>\n",
      "   https://finance.yahoo.com/blogs/author/melody-hahm-20151026/\n",
      "  </loc>\n",
      " </url>\n",
      " <url>\n",
      "  <loc>\n",
      "   https://finance.yahoo.com/blogs/author/nicole-sinclair/\n",
      "  </loc>\n",
      " </url>\n",
      " <url>\n",
      "  <loc>\n",
      "   https://finance.yahoo.com/blogs/author/rick-newman/\n",
      "  </loc>\n",
      " </url>\n",
      " <url>\n",
      "  <loc>\n",
      "   https://finance.yahoo.com/blogs/off-the-cuff/\n",
      "  </loc>\n",
      " </url>\n",
      " <url>\n",
      "  <\n"
     ]
    }
   ],
   "source": [
    "r = requests.get('https://finance.yahoo.com/sitemap_en-us_desktop_index.xml', headers = my_headers)\n",
    "\n",
    "soup = bs4.BeautifulSoup(r.content)\n",
    "\n",
    "print(soup.prettify()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to print more characters, you would see that there are URLS that follow the form ` https://finance.yahoo.com/sector/...`. These pages report stock information for top companies operating in the associated sector. The following code block shows how we can use BeautifulSoup to extract all of the `loc` elements that include the word `sector` in the associated text and store them in a list called `sector_urls`. Note how we are insuring that the returned URLS do not match any of the partial strings stored in our list of `prohibited_paths`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://finance.yahoo.com/sector/ms_basic_materials not prohibited\n",
      "https://finance.yahoo.com/sector/ms_communication_services not prohibited\n",
      "https://finance.yahoo.com/sector/ms_consumer_cyclical not prohibited\n",
      "https://finance.yahoo.com/sector/ms_consumer_defensive not prohibited\n",
      "https://finance.yahoo.com/sector/ms_energy not prohibited\n",
      "https://finance.yahoo.com/sector/ms_financial_services not prohibited\n",
      "https://finance.yahoo.com/sector/ms_healthcare not prohibited\n",
      "https://finance.yahoo.com/sector/ms_industrials not prohibited\n",
      "https://finance.yahoo.com/sector/ms_real_estate not prohibited\n",
      "https://finance.yahoo.com/sector/ms_technology not prohibited\n",
      "https://finance.yahoo.com/sector/ms_utilities not prohibited\n"
     ]
    }
   ],
   "source": [
    "sector_urls = []\n",
    "for loc_tag in soup.find_all('loc'):\n",
    "    if 'sector' in loc_tag.text:\n",
    "        prohibited = False\n",
    "        for path in prohibited_paths:\n",
    "            if path in loc_tag.text:\n",
    "                print('Path prohibited!')\n",
    "                prohibited = True\n",
    "        if not prohibited:\n",
    "            print(f'{loc_tag.text} not prohibited')\n",
    "            sector_urls.append(loc_tag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block prints the first URl in our `sector_urls` list. If you visit the site with your web browser, you sill see that the page displays a table of related stocks and associated information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://finance.yahoo.com/sector/ms_basic_materials\n"
     ]
    }
   ],
   "source": [
    "current_sector_loc = sector_urls[0]\n",
    "print(sector_urls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the HTML of the previous URL, you will see that the table is enclosed in a set of `<table>` tags. The following code block \n",
    "1. requests the HTML associated with the URL, \n",
    "2. converts the response to a `soup` object, \n",
    "3. identifies all elements enclosed in `<table>` tags and stores the associated HTML in a list named `tables`, \n",
    "4. prints the number of items in the `tables` object, and\n",
    "5. prints the first 5,000 characters of the first item in the `tables` list.\n",
    "\n",
    "Note how the HTML for the tables uses the `<tr>`, `<th>`, and `<td>` to achieve the desired structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tables object has 1 item(s).\n",
      "\n",
      "The first item in the tables object is:\n",
      "----------------------------------------------------------------------\n",
      "<table class=\"W(100%)\">\n",
      " <thead>\n",
      "  <tr class=\"C($tertiaryColor) BdB Bdbc($seperatorColor)\">\n",
      "   <th class=\"Ta(start) Pstart(6px) Pend(10px) Miw(90px) Bgc($lv3BgColor) Fz(xs) Va(m) Py(5px)! Cur(p) Bgc($hoverBgColor):h Fw(400)! Ta(start) Start(0) Pend(10px) Pos(st) Bgc($lv3BgColor) Z(1) Ta(start)!\">\n",
      "    <label class=\"Ta(c) Pos(r) Va(tb) Pend(5px) D(n)--print\">\n",
      "     <input class=\"Pos(a) V(h)\" type=\"checkbox\"/>\n",
      "     <svg class=\"Va(m)! H(16px) W(16px) Stk($plusGray)! Fill($plusGray)! Cur(p)\" data-icon=\"checkbox-unchecked\" height=\"16\" style=\"fill:#000;stroke:#000;stroke-width:0;vertical-align:bottom\" viewbox=\"0 0 24 24\" width=\"16\">\n",
      "      <path d=\"M3 3h18v18H3V3zm19-2H2c-.553 0-1 .448-1 1v20c0 .552.447 1 1 1h20c.552 0 1-.448 1-1V2c0-.552-.448-1-1-1z\">\n",
      "      </path>\n",
      "     </svg>\n",
      "    </label>\n",
      "    Symbol\n",
      "    <div class=\"W(3px) Pend(5px) Pos(a) Start(100%) T(0) H(100%) Bg($pfColumnFakeShadowGradient) Pe(n)\">\n",
      "    </div>\n",
      "   </th>\n",
      "   <th class=\"Ta(start) Px(10px) Bgc($lv3BgColor) Fz(xs) Va(m) Py(5px)! Cur(p) Bgc($hoverBgColor):h Fw(400)!\">\n",
      "    Name\n",
      "   </th>\n",
      "   <th class=\"Ta(end) Pstart(20px) Bgc($lv3BgColor) Fz(xs) Va(m) Py(5px)! Cur(p) Bgc($hoverBgColor):h Fw(400)!\">\n",
      "    Price (Intraday)\n",
      "   </th>\n",
      "   <th class=\"Ta(end) Pstart(20px) Bgc($lv3BgColor) Fz(xs) Va(m) Py(5px)! Cur(p) Bgc($hoverBgColor):h Fw(400)!\">\n",
      "    Change\n",
      "   </th>\n",
      "   <th class=\"Ta(end) Pstart(20px) Bgc($lv3BgColor) Fz(xs) Va(m) Py(5px)! Cur(p) Bgc($hoverBgColor):h Fw(400)!\">\n",
      "    % Change\n",
      "   </th>\n",
      "   <th class=\"Ta(end) Pstart(20px) Bgc($lv3BgColor) Fz(xs) Va(m) Py(5px)! Cur(p) Bgc($hoverBgColor):h Fw(400)!\">\n",
      "    Volume\n",
      "   </th>\n",
      "   <th class=\"Ta(end) Pstart(20px) Bgc($lv3BgColor) Fz(xs) Va(m) Py(5px)! Fw(400)!\">\n",
      "    Avg Vol (3 month)\n",
      "   </th>\n",
      "   <th class=\"Ta(end) Pstart(20px) Pend(10px) W(120px) Bgc($lv3BgColor) Fz(xs) Va(m) Py(5px)! Cur(p) Bgc($hoverBgColor):h C($primaryColor) Fw(500)\">\n",
      "    Market Cap\n",
      "    <svg class=\"Va(b)! W(14px) H(14px) Fill($primaryColor)! Stk($primaryColor)! Cur(p)\" data-icon=\"caret-down\" height=\"48\" style=\"fill:#000;stroke:#000;stroke-width:0;vertical-align:bottom\" viewbox=\"0 0 48 48\" width=\"48\">\n",
      "     <path d=\"M24.21 33.173l12.727-12.728c.78-.78.78-2.048 0-2.828-.78-.78-2.047-.78-2.828 0l-9.9 9.9-9.9-9.9c-.78-.78-2.047-.78-2.827 0-.78.78-.78 2.047 0 2.828L24.21 33.173z\">\n",
      "     </path>\n",
      "    </svg>\n",
      "   </th>\n",
      "   <th class=\"Ta(end) Pstart(20px) Bgc($lv3BgColor) Fz(xs) Va(m) Py(5px)! Cur(p) Bgc($hoverBgColor):h Fw(400)!\">\n",
      "    PE Ratio (TTM)\n",
      "   </th>\n",
      "   <th class=\"Ta(end) Pstart(20px) Pend(6px) Bgc($lv3BgColor) Fz(xs) Va(m) Py(5px)! Fw(400)!\">\n",
      "    52 Week Range\n",
      "   </th>\n",
      "  </tr>\n",
      " </thead>\n",
      " <tbody>\n",
      "  <tr class=\"simpTblRow Bgc($hoverBgColor):h BdB Bdbc($seperatorColor) Bdbc($tableBorderBlue):h H(32px) Bgc($lv2BgColor)\">\n",
      "   <td aria-label=\"Symbol\" class=\"Va(m) Ta(start) Pstart(6px) Pend(10px) Miw(90px) Start(0) Pend(10px) simpTblRow:h_Bgc($hoverBgColor) Pos(st) Bgc($lv3BgColor) Z(1) Bgc($lv2BgColor) Ta(start)! Fz(s)\" colspan=\"\">\n",
      "    <label class=\"Ta(c) Pos(r) Va(tb) Pend(5px) D(n)--print\">\n",
      "     <input class=\"Pos(a) V(h)\" type=\"checkbox\"/>\n",
      "     <svg class=\"Va(m)! H(16px) W(16px) Stk($plusGray)! Fill($plusGray)! Cur(p)\" data-icon=\"checkbox-unchecked\" height=\"16\" style=\"fill:#000;stroke:#000;stroke-width:0;vertical-align:bottom\" viewbox=\"0 0 24 24\" width=\"16\">\n",
      "      <path d=\"M3 3h18v18H3V3zm19-2H2c-.553 0-1 .448-1 1v20c0 .552.447 1 1 1h20c.552 0 1-.448 1-1V2c0-.552-.448-1-1-1z\">\n",
      "      </path>\n",
      "     </svg>\n",
      "    </label>\n",
      "    <a class=\"Fw(600) C($linkColor)\" data-test=\"quoteLink\" href=\"/quote/BHP?p=BHP\" title=\"BHP Group Limited\">\n",
      "     BHP\n",
      "    </a>\n",
      "    <div class=\"W(3px) Pos(a) Start(100%) T(0) H(100%) Bg($pfColumnFakeShadowGradient) Pe(n) Pend(5px)\">\n",
      "    </div>\n",
      "   </td>\n",
      "   <td aria-label=\"Name\" class=\"Va(m) Ta(start) Px(10px) Fz(s)\" colspan=\"\">\n",
      "    BHP Group Limited\n",
      "   </td>\n",
      "   <td aria-label=\"Price (Intraday)\" class=\"Va(m) Ta(end) Pstart(20px) Fw(600) Fz(s)\" colspan=\"\">\n",
      "    <fin-streamer active=\"\" class=\"\" data-field=\"regularMarketPrice\" data-pricehint=\"2\" data-symbol=\"BHP\" data-test=\"colorChange\" data-trend=\"none\" value=\"78.295\">\n",
      "     78.29\n",
      "    </fin-streamer>\n",
      "   </td>\n",
      "   <td aria-label=\"Change\" class=\"Va(m) Ta(end) Pstart(20px) Fw(600) Fz(s)\" colspan=\"\">\n",
      "    <fin-streamer active=\"\" class=\"Fw(600)\" data-field=\"regularMarketChange\" data-pricehint=\"2\" data-symbol=\"BHP\" data-test=\"colorChange\" data-trend=\"txt\" value=\"-1.0050049\">\n",
      "     <span class=\"C($negativeColor)\">\n",
      "      -1.01\n",
      "     </span>\n",
      "    </fin-streamer>\n",
      "   </td>\n",
      "   <td aria-label=\"% Change\" class=\"Va(m) Ta(end) Pstart(20px) Fw(600) Fz(s)\" colspan=\"\">\n",
      "    <fin-streamer active=\"\" class=\"Fw(600)\" data-field=\"regularMarketChangePercent\" data-pricehint=\"2\" data-symbol=\"BHP\" data-test=\"colorChange\" data-trend=\"txt\" value=\"-1.2673453\">\n",
      "     <span class=\"C($negativeColor)\">\n",
      "      -1.27%\n",
      "     </span>\n",
      "    </fin-streamer>\n",
      "   </td>\n",
      "   <td aria-label=\"Volume\" class=\"Va(m) Ta(end) Pstart(20px) Fz(s)\" colspan=\"\">\n",
      "    <fin-streamer active=\"\" class=\"\" data-field=\"regularMarketVolume\" data-pricehint=\"2\" data-symbol=\"B\n"
     ]
    }
   ],
   "source": [
    "current_sector_loc = sector_urls[0]\n",
    "\n",
    "r = requests.get(current_sector_loc)\n",
    "soup = bs4.BeautifulSoup(r.content)\n",
    "\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "print(f'The tables object has {len(tables)} item(s).\\n')\n",
    "\n",
    "print(f'The first item in the tables object is:\\n{\"-\"*70}\\n{tables[0].prettify()[:5000]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block shows how we can use a loop to iterate over all of the sectors, collecting the data stored in the table and using it to construct a pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Change</th>\n",
       "      <th>%Change</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Avg Volume (3 month)</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>PE Ratio</th>\n",
       "      <th>52 Week Range</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Scrape Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BHP</td>\n",
       "      <td>BHP Group Limited</td>\n",
       "      <td>78.29</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>-1.27%</td>\n",
       "      <td>1.324M</td>\n",
       "      <td>6.064M</td>\n",
       "      <td>278.001B</td>\n",
       "      <td>11.77</td>\n",
       "      <td></td>\n",
       "      <td>ms_basic_materials</td>\n",
       "      <td>04-04-2022 12:11:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIN</td>\n",
       "      <td>Linde plc</td>\n",
       "      <td>320.46</td>\n",
       "      <td>-2.27</td>\n",
       "      <td>-0.70%</td>\n",
       "      <td>551,590</td>\n",
       "      <td>2.338M</td>\n",
       "      <td>162.712B</td>\n",
       "      <td>43.72</td>\n",
       "      <td></td>\n",
       "      <td>ms_basic_materials</td>\n",
       "      <td>04-04-2022 12:11:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RIO</td>\n",
       "      <td>Rio Tinto Group</td>\n",
       "      <td>81.02</td>\n",
       "      <td>-1.66</td>\n",
       "      <td>-2.01%</td>\n",
       "      <td>1.793M</td>\n",
       "      <td>5.096M</td>\n",
       "      <td>131.287B</td>\n",
       "      <td>6.26</td>\n",
       "      <td></td>\n",
       "      <td>ms_basic_materials</td>\n",
       "      <td>04-04-2022 12:11:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VALE</td>\n",
       "      <td>Vale S.A.</td>\n",
       "      <td>21.12</td>\n",
       "      <td>+0.30</td>\n",
       "      <td>+1.42%</td>\n",
       "      <td>15.887M</td>\n",
       "      <td>37.546M</td>\n",
       "      <td>102.346B</td>\n",
       "      <td>4.07</td>\n",
       "      <td></td>\n",
       "      <td>ms_basic_materials</td>\n",
       "      <td>04-04-2022 12:11:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CTA-PB</td>\n",
       "      <td>E. I. du Pont de Nemours and Company</td>\n",
       "      <td>95.10</td>\n",
       "      <td>+0.05</td>\n",
       "      <td>+0.05%</td>\n",
       "      <td>478</td>\n",
       "      <td>1,627</td>\n",
       "      <td>82.528B</td>\n",
       "      <td>N/A</td>\n",
       "      <td></td>\n",
       "      <td>ms_basic_materials</td>\n",
       "      <td>04-04-2022 12:11:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Symbol                                  Name   Price Change %Change  \\\n",
       "0     BHP                     BHP Group Limited   78.29  -1.01  -1.27%   \n",
       "1     LIN                             Linde plc  320.46  -2.27  -0.70%   \n",
       "2     RIO                       Rio Tinto Group   81.02  -1.66  -2.01%   \n",
       "3    VALE                             Vale S.A.   21.12  +0.30  +1.42%   \n",
       "4  CTA-PB  E. I. du Pont de Nemours and Company   95.10  +0.05  +0.05%   \n",
       "\n",
       "    Volume Avg Volume (3 month) Market Cap PE Ratio 52 Week Range  \\\n",
       "0   1.324M               6.064M   278.001B    11.77                 \n",
       "1  551,590               2.338M   162.712B    43.72                 \n",
       "2   1.793M               5.096M   131.287B     6.26                 \n",
       "3  15.887M              37.546M   102.346B     4.07                 \n",
       "4      478                1,627    82.528B      N/A                 \n",
       "\n",
       "               Sector          Scrape Time  \n",
       "0  ms_basic_materials  04-04-2022 12:11:22  \n",
       "1  ms_basic_materials  04-04-2022 12:11:22  \n",
       "2  ms_basic_materials  04-04-2022 12:11:22  \n",
       "3  ms_basic_materials  04-04-2022 12:11:22  \n",
       "4  ms_basic_materials  04-04-2022 12:11:22  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = []\n",
    "for current_sector_loc in sector_urls:\n",
    "    r = requests.get(current_sector_loc)\n",
    "    soup = bs4.BeautifulSoup(r.content)\n",
    "\n",
    "    for current_row in soup.find_all('tr'):\n",
    "        row_list = []\n",
    "        for current_data in current_row.find_all('td'):\n",
    "            row_list.append(current_data.text)\n",
    "        if row_list:\n",
    "            row_list.append(current_sector_loc.split('/')[-1])\n",
    "            row_list.append(datetime.datetime.now().strftime('%m-%d-%Y %H:%M:%S'))\n",
    "            data_list.append(row_list)\n",
    "    \n",
    "columns = ['Symbol', 'Name', 'Price', 'Change', '%Change', \n",
    "           'Volume', 'Avg Volume (3 month)', 'Market Cap', \n",
    "           'PE Ratio', '52 Week Range', 'Sector', 'Scrape Time']\n",
    "\n",
    "all_data = pd.DataFrame(data_list, columns = columns)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia\n",
    "\n",
    "Just to demonstrate a (slightly) more complex harvesting task, let's write some code to collect headlines from Wikipedia pages. As before, let's first check the `robots.txt` file, which is much more extensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = requests.get('https://en.wikipedia.org/robots.txt')\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block creates a list of prohibited paths for a general web scraping application and displays the first 30 items in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prohibited_paths = []\n",
    "current_user_agent = None\n",
    "for line in r.text.split('\\n'):\n",
    "    if 'User-agent' in line:\n",
    "        current_user_agent = line.strip('User-agent: ')\n",
    "    if current_user_agent is not None:\n",
    "        if current_user_agent.strip() == '*':\n",
    "            if 'Disallow: ' in line:\n",
    "                prohibited_paths.append(line.strip('Disallow: '))\n",
    "                \n",
    "prohibited_paths[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you browse through a few Wikipedia pages, you will notice that the links use a very consitent naming pattern. Suppose, we want to try the phrases in the `words_to_try` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_try = ['Stochastic_optimization', \n",
    "                'Robust_optimization',\n",
    "                'Nonparametric_regression',\n",
    "                'Data_warehouse',\n",
    "                'tHis_wIll_nOt_wErk',\n",
    "                'Integer_programming',\n",
    "                'Cluster_analysis']\n",
    "\n",
    "base_url = 'https://en.wikipedia.org/wiki/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code attempts to access the pages defined by our `words_to_try` object and returns a list of the headlines along with the associated word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = []\n",
    "\n",
    "for current_word in words_to_try:\n",
    "    current_url = base_url + current_word\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(current_url)\n",
    "        soup = bs4.BeautifulSoup(r.content)\n",
    "\n",
    "        for headline in soup.find_all('span', attrs = {'class':'mw-headline'}):\n",
    "            if 'See also' in headline:\n",
    "                break\n",
    "            else:\n",
    "                headlines.append([headline.text, current_word])\n",
    "    except Exception as e:\n",
    "        print(f'{type(e).__name__} on {current_url}')\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "for row in headlines:\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
